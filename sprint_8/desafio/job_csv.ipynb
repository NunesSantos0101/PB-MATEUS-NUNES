{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import functions as F\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "\n",
    "movies_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"tituloPincipal\", StringType(), True),\n",
    "    StructField(\"tituloOriginal\", StringType(), True),\n",
    "    StructField(\"anoLancamento\", IntegerType(), True),\n",
    "    StructField(\"tempoMinutos\", IntegerType(), True),\n",
    "    StructField(\"genero\", StringType(), True),\n",
    "    StructField(\"notaMedia\", FloatType(), True),\n",
    "    StructField(\"numeroVotos\", IntegerType(), True),\n",
    "    StructField(\"generoArtista\", StringType(), True),\n",
    "    StructField(\"personagem\", StringType(), True),\n",
    "    StructField(\"nomeArtista\", StringType(), True),\n",
    "    StructField(\"anoNascimento\", IntegerType(), True),\n",
    "    StructField(\"anoFalecimento\", IntegerType(), True),\n",
    "    StructField(\"profissao\", StringType(), True),\n",
    "    StructField(\"titulosMaisConhecidos\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "series_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"tituloPincipal\", StringType(), True),\n",
    "    StructField(\"tituloOriginal\", StringType(), True),\n",
    "    StructField(\"anoLancamento\", IntegerType(), True),\n",
    "    StructField(\"anoTermino\", IntegerType(), True),\n",
    "    StructField(\"tempoMinutos\", IntegerType(), True),\n",
    "    StructField(\"genero\", StringType(), True),\n",
    "    StructField(\"notaMedia\", FloatType(), True),\n",
    "    StructField(\"numeroVotos\", IntegerType(), True),\n",
    "    StructField(\"generoArtista\", StringType(), True),\n",
    "    StructField(\"personagem\", StringType(), True),\n",
    "    StructField(\"nomeArtista\", StringType(), True),\n",
    "    StructField(\"anoNascimento\", IntegerType(), True),\n",
    "    StructField(\"anoFalecimento\", IntegerType(), True),\n",
    "    StructField(\"profissao\", StringType(), True),\n",
    "    StructField(\"titulosMaisConhecidos\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Data atual\n",
    "current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "# Constantes de caminhos S3\n",
    "RAW_ZONE_PATH = \"s3://data-lake-mateus/Raw/Local/CSV\"\n",
    "TRUSTED_ZONE_PATH = \"s3://data-lake-mateus/Trusted/Local/PARQUET\"\n",
    "\n",
    "# Função para processar dados\n",
    "def process_data(entity, schema):\n",
    "    raw_path = f\"{RAW_ZONE_PATH}/{entity}/2024/11/28/{entity.lower()}.csv\"\n",
    "    trusted_path = f\"{TRUSTED_ZONE_PATH}/{entity}/{current_date}/\"\n",
    "    \n",
    "    # Leitura dos dados\n",
    "    df_raw = spark.read.option(\"delimiter\", \"|\").csv(raw_path, header=True, schema=schema)\n",
    "    \n",
    "    # Limpeza dos dados\n",
    "    df_clean = (\n",
    "    df_raw\n",
    "    .dropDuplicates()\n",
    "    .dropna(how=\"all\")\n",
    "    .select([\n",
    "        F.when(F.col(col) == \"\\\\N\", None).otherwise(F.col(col)).alias(col) \n",
    "        for col in df_raw.columns\n",
    "    ])\n",
    "    .withColumn(\"id\", F.regexp_replace(F.col(\"id\"), \"[^0-9]\", \"\").cast(IntegerType()))\n",
    "    .withColumn(\n",
    "        \"titulosMaisConhecidos\",\n",
    "        F.when(\n",
    "            F.col(\"titulosMaisConhecidos\").isNotNull(),\n",
    "            F.concat_ws(\n",
    "                \",\", \n",
    "                F.expr(\"transform(split(titulosMaisConhecidos, ','), x -> cast(regexp_replace(x, '[^0-9]', '') as int))\")\n",
    "            )\n",
    "        ).otherwise(None)\n",
    "    )\n",
    ")\n",
    "\n",
    "    \n",
    "    \n",
    "    df_clean.write.mode(\"overwrite\").format(\"parquet\").save(trusted_path)\n",
    "    print(f\"Dados do {entity} processados e salvos em: {trusted_path}\")\n",
    "\n",
    "# Processar filmes e séries\n",
    "process_data(\"Movies\", movies_schema)\n",
    "process_data(\"Series\", series_schema)\n",
    "\n",
    "\n",
    "job.commit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
